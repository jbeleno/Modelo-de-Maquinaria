# ğŸšœ Modelo de PredicciÃ³n de Consumo de Combustible para Maquinaria AgrÃ­cola

## ğŸ¯ DescripciÃ³n del Proyecto

Este proyecto implementa modelos de machine learning para predecir el consumo de combustible en maquinaria agrÃ­cola utilizando un dataset completo de **32,060 muestras** con **16 variables de entrada**. Se evaluaron mÃºltiples algoritmos para encontrar el modelo mÃ¡s preciso y confiable.

## ğŸ“Š Dataset

- **TamaÃ±o:** 32,060 muestras
- **Variables de entrada:** 16 caracterÃ­sticas
- **Variable objetivo:** Consumo total de combustible (L)
- **Rango de consumo real:** 1.34 - 455.18 L
- **Consumo promedio real:** 53.53 L

### Variables del Dataset

| Variable | Tipo | DescripciÃ³n |
|----------|------|-------------|
| Pnominal(kW) | NumÃ©rica | Potencia nominal del motor |
| T(Â°C) | NumÃ©rica | Temperatura ambiente |
| Implemento | CategÃ³rica | Tipo de implemento agrÃ­cola |
| k_base | NumÃ©rica | Coeficiente base |
| n | NumÃ©rica | Factor de eficiencia |
| Ancho(m) | NumÃ©rica | Ancho del implemento |
| Profundidad(m) | NumÃ©rica | Profundidad de trabajo |
| Textura | CategÃ³rica | Textura del suelo |
| Humedad(%) | NumÃ©rica | Humedad del suelo |
| Velocidad(km/h) | NumÃ©rica | Velocidad de trabajo |
| Masa_total(kg) | NumÃ©rica | Masa total del equipo |
| Pendiente(%) | NumÃ©rica | Pendiente del terreno |
| Tipo_suelo | CategÃ³rica | Tipo de suelo |
| RPM | NumÃ©rica | Revoluciones por minuto |
| Duracion(h) | NumÃ©rica | DuraciÃ³n de la operaciÃ³n |

## ğŸ¤– Modelos Implementados

Se evaluaron los siguientes algoritmos de machine learning:

- **Random Forest Regressor**
- **XGBoost Regressor**
- **Gradient Boosting Regressor**
- **Ensemble (Promedio de todos los modelos)**

## ğŸ“ˆ Resultados de Rendimiento

### ğŸ† Ranking de Modelos (por Accuracy)

| PosiciÃ³n | Modelo | Accuracy (%) | RÂ² | RMSE (L) | MAE (L) |
|----------|--------|--------------|----|---------|---------| 
| ğŸ¥‡ **1Â°** | **Random Forest** | **87.14%** | **0.9017** | **13.91** | **7.16** |
| ğŸ¥ˆ **2Â°** | **Gradient Boosting** | **83.51%** | **0.8730** | **15.81** | **8.72** |
| ğŸ¥‰ **3Â°** | **XGBoost** | **82.86%** | **0.8694** | **16.03** | **8.92** |
| 4Â° | **Ensemble** | **84.69%** | **0.8849** | **15.05** | **8.18** |

## ğŸ“Š AnÃ¡lisis EstadÃ­stico Detallado

### ğŸ“ˆ Tabla Comparativa Completa de Rendimiento

| Modelo | RÂ² | RMSE (L) | MAE (L) | Accuracy (%) | Media PredicciÃ³n (L) | Std PredicciÃ³n (L) | Min PredicciÃ³n (L) | Max PredicciÃ³n (L) |
|--------|----|---------|---------|--------------|---------------------|-------------------|-------------------|-------------------|
| **Random Forest** | **0.9017** | **13.91** | **7.16** | **87.14%** | **53.74** | **40.61** | **3.96** | **305.32** |
| Gradient Boosting | 0.8730 | 15.81 | 8.72 | 83.51% | 53.63 | 40.55 | 4.57 | 363.47 |
| XGBoost | 0.8694 | 16.03 | 8.92 | 82.86% | 53.63 | 40.38 | 4.88 | 357.63 |

### ğŸ¥‡ Mejor Modelo: Random Forest

**ğŸ¯ Rendimiento Superior:**
- **Accuracy: 87.14%** - El mÃ¡s preciso de todos los modelos
- **RÂ²: 0.9017** - Explica el 90.17% de la varianza
- **RMSE: 13.91 L** - Error promedio mÃ¡s bajo
- **MAE: 7.16 L** - Error absoluto mÃ¡s pequeÃ±o

**ğŸ“Š EstadÃ­sticas de PredicciÃ³n:**
- Media de predicciÃ³n: 53.74 L
- DesviaciÃ³n estÃ¡ndar: 40.61 L
- Rango: 3.96 - 305.32 L

**âœ… PrecisiÃ³n por Rangos:**
- 31.60% de predicciones con error â‰¤ 5%
- 58.55% de predicciones con error â‰¤ 10%
- 82.50% de predicciones con error â‰¤ 20%

### ğŸ”— AnÃ¡lisis del Ensemble (Promedio)

**ğŸ“Š Rendimiento del Ensemble:**
- **Accuracy: 84.69%** - Mejor que XGBoost pero inferior a Random Forest
- **RÂ²: 0.8849** - Explica el 88.49% de la varianza
- **RMSE: 15.05 L** - Error intermedio
- **MAE: 8.18 L** - Error absoluto moderado

**ğŸ“ˆ CaracterÃ­sticas:**
- Media de predicciÃ³n: 53.67 L
- DesviaciÃ³n estÃ¡ndar: 40.42 L
- Variabilidad entre modelos: 1.61 L (baja variabilidad)

**âš ï¸ ObservaciÃ³n Importante:**
El ensemble no mejorÃ³ el rendimiento del mejor modelo individual (Random Forest), lo que indica que Random Forest ya captura muy bien los patrones del dataset.

## ğŸ“Š AnÃ¡lisis de Errores

### ğŸ” DistribuciÃ³n de Errores Absolutos

| Modelo | Media Error (L) | Std Error (L) | Min Error (L) | Max Error (L) |
|--------|----------------|---------------|---------------|---------------|
| **Random Forest** | **-0.21** | **13.91** | **-123.83** | **166.69** |
| XGBoost | -0.10 | 16.03 | -126.81 | 146.60 |
| Gradient Boosting | -0.10 | 15.81 | -140.02 | 157.93 |
| Ensemble | -0.13 | 15.05 | -127.51 | 152.80 |

### ğŸ“ˆ DistribuciÃ³n de Errores Relativos

| Modelo | Media Error (%) | Std Error (%) | Mediana Error (%) |
|--------|----------------|---------------|-------------------|
| **Random Forest** | **12.86%** | **16.11%** | **8.15%** |
| XGBoost | 17.14% | 21.77% | 11.18% |
| Gradient Boosting | 16.49% | 19.96% | 10.92% |
| Ensemble | 15.31% | 18.73% | 9.95% |

### ğŸ“Š EstadÃ­sticas de Errores por Cuartiles

| Modelo | Q1 Error (L) | Q2 Error (L) | Q3 Error (L) |
|--------|--------------|--------------|--------------|
| **Random Forest** | **-3.20** | **-0.08** | **2.30** |
| XGBoost | -4.26 | -0.12 | 3.42 |
| Gradient Boosting | -4.17 | -0.03 | 3.26 |
| Ensemble | -3.86 | -0.08 | 2.93 |

## ğŸ¯ Conclusiones y Recomendaciones

### âœ… Fortalezas del Random Forest

1. **Mayor PrecisiÃ³n:** 87.14% de accuracy, significativamente superior a los otros modelos
2. **Menor Error:** RMSE de 13.91 L vs 15-16 L de los otros modelos
3. **Mejor Consistencia:** 82.50% de predicciones con error â‰¤ 20%
4. **Estabilidad:** Menor variabilidad en los errores

### ğŸ“Š ComparaciÃ³n con el Dataset Real

- **Consumo real promedio:** 53.53 L
- **Consumo real std:** 44.37 L
- **Rango real:** 1.34 - 455.18 L

**ObservaciÃ³n:** Los modelos predicen correctamente la media (â‰ˆ53.6 L) pero con menor variabilidad (â‰ˆ40.4 L vs 44.4 L real), lo que sugiere que los modelos son conservadores en sus predicciones extremas.

### ğŸ¯ Recomendaciones de Uso

#### ğŸ¥‡ **Para Aplicaciones CrÃ­ticas:**
- **Usar Random Forest** - Mayor precisiÃ³n y consistencia
- **Confianza alta** para predicciones dentro del rango de entrenamiento
- **Monitorear** predicciones extremas (>300 L)

#### ğŸ”„ **Para Aplicaciones Generales:**
- **Random Forest** sigue siendo la mejor opciÃ³n
- **Ensemble** como alternativa si se requiere mayor robustez
- **Validar** predicciones con datos histÃ³ricos cuando sea posible

#### âš ï¸ **Limitaciones Identificadas:**
1. **SobreestimaciÃ³n conservadora:** Los modelos tienden a ser conservadores
2. **Errores en extremos:** Mayor error en consumos muy altos o muy bajos
3. **Variabilidad reducida:** Predicen con menor variabilidad que la realidad

## ğŸ“ Archivos del Proyecto

### ğŸ“Š Datos
- `datos_maquinaria_consumo.csv` - Dataset completo con 32,060 muestras
- `predicciones_completas_detalladas.csv` - Predicciones detalladas de todos los modelos

### ğŸ¤– Modelos Entrenados
- `random_forest_optimizado.pkl` - Mejor modelo (87.14% accuracy)
- `xgboost_optimizado.pkl` - Modelo XGBoost optimizado
- `gradient_boosting_optimizado.pkl` - Modelo Gradient Boosting optimizado

### ğŸ“‹ DocumentaciÃ³n
- `modelos_finales_consumo.ipynb` - Notebook con el cÃ³digo completo
- `evaluacion_completa_modelos.txt` - Resultados detallados de evaluaciÃ³n

## ğŸš€ InstalaciÃ³n y Uso

### Requisitos del Sistema
- Python 3.7+
- 8GB RAM mÃ­nimo recomendado
- 2GB espacio en disco

### InstalaciÃ³n de Dependencias
```bash
pip install -r requirements.txt
```

### Uso del Modelo
```python
import joblib
import pandas as pd

# Cargar el modelo entrenado
modelo = joblib.load('random_forest_optimizado.pkl')

# Preparar datos de entrada (ejemplo)
datos_entrada = pd.DataFrame({
    'Pnominal(kW)': [150],
    'T(Â°C)': [25],
    'Implemento': ['Arado'],
    'k_base': [1.2],
    'n': [0.8],
    'Ancho(m)': [3.0],
    'Profundidad(m)': [0.3],
    'Textura': ['Media'],
    'Humedad(%)': [15],
    'Velocidad(km/h)': [8],
    'Masa_total(kg)': [2500],
    'Pendiente(%)': [5],
    'Tipo_suelo': ['Arcilloso'],
    'RPM': [1500],
    'Duracion(h)': [4]
})

# Realizar predicciÃ³n
prediccion = modelo.predict(datos_entrada)
print(f"Consumo predicho: {prediccion[0]:.2f} L")
```

## ğŸ“ˆ MÃ©tricas de Calidad del Dataset

- **TamaÃ±o:** 32,060 muestras (excelente para entrenamiento)
- **Variables:** 16 caracterÃ­sticas (buena diversidad)
- **Rango de consumo:** 1.34 - 455.18 L (amplio rango)
- **DistribuciÃ³n:** Media 53.53 L, Std 44.37 L (distribuciÃ³n realista)

## ğŸ”® Perspectivas Futuras

### ğŸš€ Mejoras Potenciales:
1. **RecolecciÃ³n de mÃ¡s datos** en rangos extremos
2. **Feature engineering** adicional
3. **TÃ©cnicas de ensemble** mÃ¡s sofisticadas
4. **ValidaciÃ³n cruzada** temporal si hay dependencia temporal

### ğŸ“Š Monitoreo Continuo:
1. **Tracking de accuracy** en producciÃ³n
2. **DetecciÃ³n de drift** en los datos
3. **Reentrenamiento periÃ³dico** con nuevos datos
4. **ValidaciÃ³n** con casos reales

---

*ğŸ“… EvaluaciÃ³n realizada con dataset completo de 32,060 muestras*  
*ğŸ¤– Modelos evaluados: Random Forest, XGBoost, Gradient Boosting, Ensemble*  
*ğŸ¯ Mejor modelo: Random Forest con 87.14% de accuracy*
